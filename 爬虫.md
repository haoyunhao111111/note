## 爬虫

>  模拟浏览器发送网络请求，获取响应，按照规则提取数据的程序

- 模拟浏览器发送网络请求：照着浏览器发送一模一样的请求，获取和浏览器一模一样的数据

### 数据去向

- 呈现在网页或者app上
- 用于数据分析，机器学习

### 浏览器请求

#### 浏览器请求url地址：

> 当前url对应的响应+css+js+图片 -->element中的内容

#### 爬虫请求url地址: 

>  当前url对应的响应

- element中的内容和爬虫获取到的url地址的响应不同，爬虫中需要以当前url地址对应的响应为准提取数据

### HTTP协议,HTTPS

#### get、post区别

1. get请求没有请求体，post有
2. post长用于登录注册
3. post请求携带的数据量比get大，常用于传输大文本的时候

#### HTTP协议之请求

- HTTP:超文本传输协议
  - 以明文形式传输
  - 效率更高，但是不安全

- HTTPS：HTTP+SSL(安全套接字层)
  - 传输之前先加密，之后解密获取内容
  - 效率低，安全

- http协议之请求
  - 请求行
  - 请求头
    - user-agent:用户代理，对方服务器能够通过user-agent知道当前请求对方资源的是什么浏览器
      - 如果我们需要模拟手机版的浏览器发送请求。对应的需要把user-agent改成手机版
    - cookie:存储用户信息，每次请求会被携带上发送给对方的浏览器
      - 要获取登录后才能访问的页面
      - 对方的服务器会通过cookie判断我们是否是一个爬虫
  - 请求体
    - get请求没有请求体
    - post请求有请求体

  #### HTTP协议之响应

  - 响应头
    - set-cookie:对方服务器通过该字段设置cookie到本地
  - 响应体
    - url地址对应的响应

  ### requests模块

  ```python
  pip install requests
  ```

  #### 发送get,post请求，获取响应

  ```python
  response=requests.get(url)   #发送get请求，请求url地址对应的响应
  response=requests.post(url,data={请求体的字典})   #发送post请求，请求url地址对应的响应
  ```

  #### response的方法

  - response.text
    - 该方式往往会出现乱码，response.encoding="UTF-8"
  - response.content.decode()
    - 把响应的二进制字节流转化为str类型
  - response.request.url    发送请求的url地址
  - response.url     response响应的url地址
  - response.request.headers    请求头
  - reqonse.headers  响应头

  #### 获取网页源码的正确打开方式

  1. response.content.decode()
  2. response.content.decode("gbk")
  3. response.text

  #### 发送带Header的请求

  > 为了模拟浏览器，获取跟浏览器一模一样的内容

  ```python
  headers={}
  ```

  